---
layout: post
title:  "AlgoTransparency and Middleware"
date: 2021-03-25
categories:
---
Earlier this week I came across [AlgoTransparency](https://www.algotransparency.org), an interest group founded by Guillaume Chaslot who many people will recognise from The Social Dilemma. AlgoTransparency has commendable aims, they wish to:

- Raise public awareness about the lack of transparency provided by the world's most significant algorithms.
- Influence international regulators with regards to policy approaches.
- Pressurise the owners of significant algorithms to make changes to the way they operate.

A digital economy with transparency at the heart of algorithm design and deployment is a worthy cause, however the extent to which this even possible cannot be ignored. As [Jenna Burrell](https://journals.sagepub.com/doi/abs/10.1177/2053951715622512) notes:

> When a computer learns and consequently builds its own representation of a classification decision, it does so without regard for human comprehension.

So, while an engineering team may be able to articulate what *inputs* were used to determine a ranking/recommendation decision, an explanation of the final *output* may beyond the understanding of its developers. You can see a vivid demonstration of this during [AlphaGo the movie](https://www.alphagomovie.com) when the software starts to play moves that leave the engineering team scratching their heads. It's also worth noting that, with respect to AlphaGo at least, we have a clear understanding of the software's goal â€“ to beat its opponent in a game of Go. The goal(s) of the ranking algorithms the general public come into contact with tend to be corporate secrets, adding a further type of opacity into the mix. Overcoming the hurdles of technical and deliberate corporate opacity will be a significant challenge. And even if it is surmountable one, users are still left with the same old algorithm. Transparency will make developers more accountable, but it won't create choice and the kind of innovation that comes with competition.

I would argue that [algorithm choice]({%- post_url 2021-02-19-roon-algorithmic-choice-middleware -%}) and a marketplace for middleware furthers the transparency cause because it makes transparency a vector by which consumers can vet their choice of algorithm. Developers who are open (as they can be) about the nature of their algorithms and the goals that its success is measured against, will surely be more appealing than those who chose to hide this information.

The idea that I continually return to is that the successful regulation of tech/platforms/algorithms will be made up of many overlapping changes rather a single headline one. Break ups diffuse power, but aren't going to make it easier to compete against YouTube. Full protocol interoperability will support new market entrants but would likely come with a new kinds of risk to personal data. Algorithm transparency and middleware do little to alter the distribution of power. I wonder if taking a more "agile" approach to regulation is what is needed, smaller changes, call them tests, that try to target specific problems rather than change everything in one go. I'm not that hopeful.
