---
layout: post
title:  "AlgoTransparency and Middleware"
date: 2021-03-26
categories:
---
Earlier this week I came across [AlgoTransparency](https://www.algotransparency.org), an interest group founded by Guillaume Chaslot who many people will recognise from The Social Dilemma. AlgoTransparency has commendable aims, they wish to:

- Raise public awareness about the lack of transparency provided by the world's most significant algorithms.
- Influence international regulators with regards to policy approaches.
- Pressurise the owners of significant algorithms to make changes to the way they operate.

This is agenda I can get behind. End users should be provided with simple explanations about how the algorithms that power any given app or website work. And that these explanations should satisfy both the need to understand the goal the algorithm has, for instance "time on site", and, to the extent that it's possible, the process that led to its final decision.<a href="#footnote1"><sup>1</sup></a>

Transparency will lead to greater public understanding about the algorithms that exercise a huge amount of power over the experiences they have while traversing the digital economy. In fact there is a comparison to be made here with the EU's fated "cookie policy". While people (myself included) lament the annoyance of consent pop-ups it's hard deny that their presence will have had a significant impact on the public's understanding of how they are being tracked as they surf the web. And while it's unlikely that many people spend time reading the descriptions of different cookies a website users, the mandated openness has created a new dataset for examination by journalists and [privacy researchers](https://www.top10vpn.com/research/).

Of course, with the cookie policy despite all the [dark patterns you're likely to come across](https://arxiv.org/abs/1909.02638) you can still opt-out. And yet with algorithms this isn't the case. Algorithms are critical to the proper functioning of many websites/apps and the developer has a full monopoly which one you use.

This is not to say the AlgoTransparency has picked the wrong fight. Any attempt to improve the public's understanding of how algorithms operate is a worthy cause in my mind. But the user cannot opt out, they are

However, users are still left with the same old algorithm, and

And while many will argue that notices explaining how algorithms work will be largely ignored,

AlphaGo also highlights another important consideration when it comes to algorithm transparency in that AlphaGo's overall goal is pretty clearcut â€“ to beat its opponent in a game of Go. However, the goals of the ranking algorithms the general public come into contact can be more complex than this. Is the goal time spent using the product? Is it to display a certain type or number of ads? Is it some interaction such as a like or retweet? Why you're being recommended something is a technical question, but it's also an economic one, and both are worthy of explanation.

adding a further type of opacity into the mix. Overcoming the twin hurdles of technical and deliberate corporate opacity will be a significant challenge. And even if it is surmountable one, users are still left with the same old algorithm. Transparency will make developers more accountable, but it won't create choice and the kind of innovation that comes with competition.

I would argue that [algorithm choice]({%- post_url 2021-02-19-roon-algorithmic-choice-middleware -%}) and a marketplace for middleware furthers the transparency cause because it makes transparency a vector by which consumers can vet their choice of algorithm. Developers who are open (as they can be) about the nature of their algorithms and the goals that its success is measured against, will surely be more appealing than those who chose to hide this information.

The idea that I continually return to is that the successful regulation of tech/platforms/algorithms will be made up of many overlapping changes rather a single headline one. Break ups diffuse power, but aren't going to make it easier to compete against YouTube. Full protocol interoperability will support new market entrants but would likely come with a new kinds of risk to personal data. Algorithm transparency and middleware do little to alter the distribution of power. I wonder if taking a more "agile" approach to regulation is what is needed, smaller changes, call them tests, that try to target specific problems rather than change everything in one go. I'm not that hopeful.

---

<p id="footnote1"><sup>1</sup>It's important to note here that full transparency may not be possible. As Jenna Burrell points out in her excellent paper on <a href="https://journals.sagepub.com/doi/abs/10.1177/2053951715622512">opacity within machine learning</a>.</p>
